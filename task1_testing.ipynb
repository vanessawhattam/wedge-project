{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Big Query is a distributed data warehouse built on a serverless architecture . We’ll discuss this framework in class. In this task you’ll upload all Wedge transaction records to Google Big Query. You’ll want to make sure that the column data types are correctly specified and you’ve properly handled the null values. \n",
    "The requirements for this task change depending on the grade you’re going for. \n",
    "Note: this assignment can be done manually or programmatically. Naturally I’d prefer it be done programmatically so that you get more practice, but that’s not required to get full credit.\n",
    "\n",
    "1. Clean the data\n",
    "    a. I need to split on the delimiter\n",
    "    b. check for a header (and add it if it doesn't have one)\n",
    "    c. fix the \\\\N and \\N  and NULL values - keep as NULL\n",
    "    d. Split them into single month dataframes\n",
    "2. Upload to GBQ\n",
    "    a. Upload each one as a separate table in a new dataset in my GBQ project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import csv\n",
    "import io\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from io import TextIOWrapper\n",
    "from shutil import move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_files = os.listdir(\"WedgeZipOfZips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters = dict()\n",
    "\n",
    "# Start by reading in all the files again.\n",
    "for this_zf in zip_files:\n",
    "    with ZipFile(\"WedgeZipOfZips/\" + this_zf, 'r') as zf:\n",
    "        zipped_files = zf.namelist()\n",
    "\n",
    "        for file_name in zipped_files:\n",
    "            input_file = zf.open(file_name, 'r')\n",
    "            input_file = io.TextIOWrapper(input_file, encoding=\"utf-8\")\n",
    "\n",
    "            # Read the first line to detect the delimiter\n",
    "            first_line = input_file.readline()\n",
    "            dialect = csv.Sniffer().sniff(sample=first_line, delimiters=[\",\", \";\", \"\\t\"])\n",
    "            detected_delimiter = dialect.delimiter\n",
    "\n",
    "            # Check if the detected delimiter is different from \",\"\n",
    "            if detected_delimiter != \",\":\n",
    "                # Change the delimiter to \",\"\n",
    "                delimiters[file_name] = \",\"\n",
    "            else:\n",
    "                delimiters[file_name] = detected_delimiter\n",
    "\n",
    "            # Reset the file back to the beginning for further processing\n",
    "            input_file.seek(0)\n",
    "\n",
    "            # Now, you can process the file using the appropriate delimiter\n",
    "            for line in input_file:\n",
    "                # Process the data rows here\n",
    "                data = line.strip().split(delimiters[file_name])\n",
    "                \n",
    "\n",
    "            print(f\"{file_name}: has delimiter: {detected_delimiter}\")\n",
    "            input_file.close()  # tidy up\n",
    "\n",
    "            if detected_delimiter == \";\":\n",
    "                move(file_name, os.path.join(semicolon_folder, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = dict()\n",
    "\n",
    "for this_zf in zip_files:\n",
    "    with ZipFile(\"WedgeZipOfZips/\" + this_zf, 'r') as zf:\n",
    "        zipped_files = zf.namelist()\n",
    "\n",
    "        for file_name in zipped_files:\n",
    "            input_file = zf.open(file_name, 'r')\n",
    "            input_file = io.TextIOWrapper(input_file, encoding=\"utf-8\")\n",
    "\n",
    "            this_delimiter = delimiters[file_name]\n",
    "\n",
    "            # Read the first line to check for the header row\n",
    "            first_line = input_file.readline()\n",
    "\n",
    "            # Check if the first line is a header row (you can customize this check)\n",
    "            is_header = any(keyword in first_line for keyword in ['datetime', 'register_no', 'description', 'trans_status', 'quantity'])\n",
    "\n",
    "            headers[file_name] = is_header\n",
    "\n",
    "            print(f\"File: {file_name}, Has Header: {is_header}\")\n",
    "\n",
    "            input_file.close()  # tidy up\n",
    "\n",
    "            # Move the file to our no_headers folder\n",
    "            if is_header:\n",
    "                move(file_name, os.path.join(no_headers, file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
